{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import featuretools as ft\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import preprocessing\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('input/train.csv', na_values=['NAN','NA','NaN','na','nan'])\n",
    "test_df = pd.read_csv('input/test.csv', na_values=['NAN','NA','NaN','na','nan'])\n",
    "X_all = pd.read_csv('input/X_all.csv', na_values=['NAN','NA','NaN','na','nan'])\n",
    "X = pd.read_csv('input/X.csv', na_values=['NAN','NA','NaN','na','nan'])\n",
    "X_test = pd.read_csv('input/X_test.csv', na_values=['NAN','NA','NaN','na','nan'])\n",
    "ft_importance_total = pd.read_csv('input/ft_importance_total.csv', na_values=['NAN','NA','NaN','na','nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05244755244755245"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['OC'][train_df['OC'] == 'open'] = 0\n",
    "train_df['OC'][train_df['OC'] == ' close'] = 1\n",
    "y = train_df['OC']\n",
    "X_id = train_df['inst_id']\n",
    "X_test_id = test_df['inst_id']\n",
    "X.fillna(X.median(), inplace=True)\n",
    "X_test.fillna(X_test.median(), inplace=True)\n",
    "y.fillna(0, inplace=True)\n",
    "imbalanced_pos_ratio = y.value_counts()[1]/y.value_counts()[0]\n",
    "imbalanced_pos_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, X, y, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgboost.DMatrix(X.values, label=y.values)\n",
    "        cvresult = xgboost.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='logloss', early_stopping_rounds=early_stopping_rounds, stratified=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    #print(cvresult)\n",
    "    #Fit the algorithm on the data\n",
    "    #alg.fit(dtrain[predictors], dtrain[target],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    #dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    #dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    #print \"\\nModel Report\"\n",
    "    #print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions)\n",
    "    #print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob)\n",
    "                    \n",
    "    #feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    #feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    #plt.ylabel('Feature Importance Score')\n",
    "    return cvresult.shape[0], cvresult.iloc[cvresult.shape[0]-1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "         learning_rate=0.1,\n",
    "         n_estimators=500,\n",
    "         objective= 'binary:logistic',\n",
    "         tree_method='gpu_exact',\n",
    "         predictor='gpu_predictor',\n",
    "         scale_pos_weight=int(1/imbalanced_pos_ratio),\n",
    "         seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 estimators 82 percentile 99 logloss 0.17515340000000001\n",
      "Iteration 2 estimators 82 percentile 98 logloss 0.1669172\n",
      "Iteration 3 estimators 82 percentile 97 logloss 0.16018939999999998\n",
      "Iteration 4 estimators 82 percentile 96 logloss 0.18223859999999997\n",
      "Iteration 5 estimators 82 percentile 95 logloss 0.19189099999999998\n",
      "Iteration 6 estimators 82 percentile 94 logloss 0.2060902\n",
      "Iteration 7 estimators 82 percentile 93 logloss 0.20623479999999997\n",
      "Iteration 8 estimators 82 percentile 92 logloss 0.20999440000000003\n",
      "Iteration 9 estimators 82 percentile 91 logloss 0.204365\n",
      "Iteration 10 estimators 82 percentile 90 logloss 0.20602499999999999\n",
      "Iteration 11 estimators 82 percentile 89 logloss 0.1996742\n",
      "Iteration 12 estimators 82 percentile 88 logloss 0.20193339999999999\n",
      "Iteration 13 estimators 82 percentile 87 logloss 0.2053778\n",
      "Iteration 14 estimators 82 percentile 86 logloss 0.2051132\n",
      "Best params {'n_estimators': 82} percentile 97 logloss 0.16018939999999998\n"
     ]
    }
   ],
   "source": [
    "min_logloss = 100000\n",
    "xgb_tunned_params = dict()\n",
    "xgb_percentile = 0\n",
    "for i in range(1,15):\n",
    "    xgb_x_cols = ft_importance_total[ft_importance_total.value >= np.percentile(ft_importance_total.value,100-i)].sort_values(by='value', ascending=False).feature\n",
    "    X2 = X[xgb_x_cols] \n",
    "    y2 = y.astype('int')\n",
    "    v_n_estimators, v_logloss = modelfit(xgb, X2, y2) \n",
    "    print('Iteration', i, 'estimators', v_n_estimators, 'percentile', 100-i, 'logloss', v_logloss)\n",
    "    if v_logloss < min_logloss:\n",
    "        xgb_tunned_params['n_estimators'] = v_n_estimators\n",
    "        xgb_percentile = 100-i\n",
    "        min_logloss = v_logloss\n",
    "print('Best params', xgb_tunned_params, 'percentile', xgb_percentile, 'logloss', min_logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "933                       employee1_enc\n",
       "934                       employee2_enc\n",
       "930                            sido_enc\n",
       "113     DIFF(shortLoan1 by ownerChange)\n",
       "935                     ownerChange_enc\n",
       "0                                  noi1\n",
       "149        DIFF(profit2 by ownerChange)\n",
       "154          DIFF(bedCount by instkind)\n",
       "186           DIFF(noe1 by ownerChange)\n",
       "93                      inventoryAsset2\n",
       "131       DIFF(OnonCAsset2 by instkind)\n",
       "91                   liquidLiabilities2\n",
       "67                             bedCount\n",
       "229            DIFF(sgg by ownerChange)\n",
       "169       DIFF(bedCount by ownerChange)\n",
       "152      DIFF(longLoan2 by ownerChange)\n",
       "615        city.STD(clients.shortLoan1)\n",
       "108         DIFF(tanAsset2 by instkind)\n",
       "84                          OnonCAsset1\n",
       "94     DIFF(OnonCAsset1 by ownerChange)\n",
       "201       DIFF(OnonCAsset1 by instkind)\n",
       "10                   liquidLiabilities1\n",
       "92                                  sgg\n",
       "83                                debt1\n",
       "12                      inventoryAsset1\n",
       "251        DIFF(shortLoan1 by instkind)\n",
       "163                  DIFF(noe2 by sido)\n",
       "789          city.STD(clients.bedCount)\n",
       "202               DIFF(sgg by instkind)\n",
       "Name: feature, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_x_cols = ft_importance_total[ft_importance_total.value >= np.percentile(ft_importance_total.value,xgb_percentile)].sort_values(by='value', ascending=False).feature\n",
    "xgb_x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "         learning_rate=0.1,\n",
    "         n_estimators=xgb_tunned_params['n_estimators'],\n",
    "         objective= 'binary:logistic',\n",
    "         tree_method='gpu_exact',\n",
    "         predictor='gpu_predictor',\n",
    "         scale_pos_weight=int(1/imbalanced_pos_ratio),\n",
    "         seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=82,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       predictor='gpu_predictor', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=19, seed=42, silent=True,\n",
       "       subsample=1, tree_method='gpu_exact')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X, y.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_class = xgb.predict(X_test)\n",
    "preds_proba = xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00477265, 0.29325062, 0.13723552, 0.06851161, 0.07501835,\n",
       "       0.12442242, 0.13544735, 0.05867784, 0.02189175, 0.16566478,\n",
       "       0.00542779, 0.26392436, 0.00970337, 0.02994373, 0.04968549,\n",
       "       0.03270299, 0.01871032, 0.20814504, 0.68903273, 0.2746539 ,\n",
       "       0.806976  , 0.1723162 , 0.7997966 , 0.20137466, 0.00743742,\n",
       "       0.01850219, 0.01723975, 0.00914306, 0.04108263, 0.00601537,\n",
       "       0.03596375, 0.00563089, 0.04006407, 0.00914992, 0.06582721,\n",
       "       0.03412053, 0.00769332, 0.01263769, 0.05864076, 0.0403929 ,\n",
       "       0.00989509, 0.05577864, 0.04142151, 0.10807236, 0.0045981 ,\n",
       "       0.10073417, 0.38611004, 0.04901055, 0.49327233, 0.06152562,\n",
       "       0.05308534, 0.00744429, 0.62181777, 0.28868556, 0.16535336,\n",
       "       0.18401875, 0.01856942, 0.00710452, 0.00490293, 0.00374117,\n",
       "       0.01051193, 0.12698258, 0.14709403, 0.75770503, 0.30449268,\n",
       "       0.14817064, 0.04698721, 0.86748934, 0.07594793, 0.12365425,\n",
       "       0.02432493, 0.30946264, 0.00785873, 0.0415432 , 0.00986539,\n",
       "       0.00463095, 0.0155751 , 0.03220299, 0.02839411, 0.01233311,\n",
       "       0.01401166, 0.1957543 , 0.23369682, 0.02563412, 0.4685635 ,\n",
       "       0.01176536, 0.16724378, 0.01331855, 0.21502778, 0.32710892,\n",
       "       0.01082633, 0.17122278, 0.01041395, 0.33621067, 0.02091197,\n",
       "       0.00532096, 0.03673759, 0.4850933 , 0.10530089, 0.3079344 ,\n",
       "       0.02331604, 0.01415402, 0.00940704, 0.00210863, 0.223764  ,\n",
       "       0.01529032, 0.03706801, 0.01317119, 0.14304748, 0.13771613,\n",
       "       0.02691147, 0.00866614, 0.9113865 , 0.29701632, 0.04882715,\n",
       "       0.04346525, 0.03058012, 0.0683566 , 0.01234717, 0.00201161,\n",
       "       0.05412606, 0.02048876, 0.67155254, 0.09738889, 0.78785425,\n",
       "       0.02733397, 0.05990503], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
